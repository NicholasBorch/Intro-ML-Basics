{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, load_wine, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## USER SELECT DATASET\n",
    "# Options: \"iris\", \"wine\", \"breast_cancer\"\n",
    "selected_dataset = \"wine\"\n",
    "###########################################\n",
    "\n",
    "\n",
    "if selected_dataset == \"iris\":\n",
    "    data = load_iris(as_frame=True)\n",
    "elif selected_dataset == \"wine\":\n",
    "    data = load_wine(as_frame=True)\n",
    "elif selected_dataset == \"breast_cancer\":\n",
    "    data = load_breast_cancer(as_frame=True)\n",
    "else:\n",
    "    raise ValueError(\"Invalid dataset selected. Choose from 'iris', 'wine', or 'breast_cancer'.\")\n",
    "\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "label_names = data.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## USER change to handle NaN: \"remove\" or \"impute\"\n",
    "handle_missing = \"remove\"\n",
    "###################################################\n",
    "\n",
    "\n",
    "if X.isnull().any().any():\n",
    "    print(\"Found NaN values.\")\n",
    "    if handle_missing == \"remove\":\n",
    "        print(\"Removing rows with NaN values...\")\n",
    "        X = X.dropna()\n",
    "        y = y[X.index]\n",
    "    elif handle_missing == \"impute\":\n",
    "        print(\"Imputing missing values with mean...\")\n",
    "        from sklearn.impute import SimpleImputer\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "        X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid option for 'handle_missing'. Choose 'remove' or 'impute'.\")\n",
    "else:\n",
    "    print(\"No missing values found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset Overview:\")\n",
    "display(X.head())\n",
    "print(\"_\"*100)\n",
    "print(\"\\nDataset Info:\")\n",
    "print(X.info())\n",
    "print(\"_\"*100)\n",
    "print(f\"\\nNumber of samples: {X.shape[0]}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(\"_\"*100)\n",
    "\n",
    "\n",
    "label_count = y.value_counts().sort_index()\n",
    "print(\"\\nLabels and their counts:\")\n",
    "for i, label in enumerate(label_names):\n",
    "    print(f\"{label}: {label_count[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save standardized data for PCA (notebook 2) and raw data for CV (notebook 3) \n",
    "preprocessed_data = {\n",
    "    \"X_scaled\": X_scaled,  # For PCA\n",
    "    \"X_raw\": X,           # For CV\n",
    "    \"y\": y,\n",
    "    \"label_names\": label_names\n",
    "}\n",
    "\n",
    "with open('preprocessed_data.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessed_data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLDM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
