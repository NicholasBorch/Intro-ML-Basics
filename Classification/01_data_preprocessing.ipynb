{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, load_wine, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User selects the dataset\n",
    "# Options: \"iris\", \"wine\", \"breast_cancer\"\n",
    "selected_dataset = \"wine\"  # Change this variable to choose a dataset\n",
    "\n",
    "# Load the selected dataset\n",
    "if selected_dataset == \"iris\":\n",
    "    data = load_iris(as_frame=True)\n",
    "elif selected_dataset == \"wine\":\n",
    "    data = load_wine(as_frame=True)\n",
    "elif selected_dataset == \"breast_cancer\":\n",
    "    data = load_breast_cancer(as_frame=True)\n",
    "else:\n",
    "    raise ValueError(\"Invalid dataset selected. Choose from 'iris', 'wine', or 'breast_cancer'.\")\n",
    "\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "label_names = data.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values found.\n"
     ]
    }
   ],
   "source": [
    "# User change to handle NaN: \"remove\" or \"impute\"\n",
    "handle_missing = \"remove\"\n",
    "\n",
    "\n",
    "if X.isnull().any().any():\n",
    "    print(\"Found NaN values.\")\n",
    "    if handle_missing == \"remove\":\n",
    "        print(\"Removing rows with NaN values...\")\n",
    "        X = X.dropna()\n",
    "        y = y[X.index]\n",
    "    elif handle_missing == \"impute\":\n",
    "        print(\"Imputing missing values with mean...\")\n",
    "        from sklearn.impute import SimpleImputer\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "        X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid option for 'handle_missing'. Choose 'remove' or 'impute'.\")\n",
    "else:\n",
    "    print(\"No missing values found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   sepal length (cm)  150 non-null    float64\n",
      " 1   sepal width (cm)   150 non-null    float64\n",
      " 2   petal length (cm)  150 non-null    float64\n",
      " 3   petal width (cm)   150 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 4.8 KB\n",
      "None\n",
      "____________________________________________________________________________________________________\n",
      "\n",
      "Number of samples: 150\n",
      "Number of features: 4\n",
      "____________________________________________________________________________________________________\n",
      "\n",
      "Labels and their counts:\n",
      "setosa: 50\n",
      "versicolor: 50\n",
      "virginica: 50\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Overview:\")\n",
    "display(X.head())\n",
    "print(\"_\"*100)\n",
    "print(\"\\nDataset Info:\")\n",
    "print(X.info())\n",
    "print(\"_\"*100)\n",
    "print(f\"\\nNumber of samples: {X.shape[0]}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(\"_\"*100)\n",
    "\n",
    "\n",
    "label_count = y.value_counts().sort_index()\n",
    "print(\"\\nLabels and their counts:\")\n",
    "for i, label in enumerate(label_names):\n",
    "    print(f\"{label}: {label_count[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save standardized data for PCA and raw data for CV\n",
    "preprocessed_data = {\n",
    "    \"X_scaled\": X_scaled,  # For PCA\n",
    "    \"X_raw\": X,           # For CV\n",
    "    \"y\": y,\n",
    "    \"label_names\": label_names\n",
    "}\n",
    "\n",
    "# Save data\n",
    "with open('preprocessed_data.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessed_data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLDM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
